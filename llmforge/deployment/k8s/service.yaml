# LLMForge vLLM Service
# Exposes the vLLM inference server

apiVersion: v1
kind: Service
metadata:
  name: vllm-service
  namespace: llmforge
  labels:
    app: vllm-inference
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "80"
spec:
  selector:
    app: vllm-inference
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8000
  type: ClusterIP

---
# LoadBalancer Service for external access
apiVersion: v1
kind: Service
metadata:
  name: vllm-external
  namespace: llmforge
  labels:
    app: vllm-inference
  annotations:
    cloud.google.com/load-balancer-type: "External"
spec:
  selector:
    app: vllm-inference
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
